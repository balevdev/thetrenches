---
title: "What If You Could <em>See Through</em> the Cloud?"
subtitle: "A Dream About Transparent Infrastructure: AnakinCloud as a Thought Experiment"
description: "What if you could see every line of code that runs your platform? A thought experiment about transparent infrastructure, built on the shoulders of giants. None of this exists yet, but maybe it should."
pubDate: 2025-01-20
category: "Infrastructure"
readTime: "22 min"
tags: ["kubernetes", "paas", "open-source", "hetzner", "rke2", "infrastructure", "devops", "philosophy"]
accent: "orange"
heroImage: "https://imagedelivery.net/MJtvjX9fb_fA1fd2F8b4_A/c24ebfde-ea2f-42f1-6515-6a51cb847b00/public"
---

import Callout from '../../components/blog/Callout.astro';
import ComparisonTable from '../../components/blog/ComparisonTable.astro';
import KeyPoint from '../../components/blog/KeyPoint.astro';
import StatGrid from '../../components/blog/StatGrid.astro';
import TechStack from '../../components/blog/TechStack.astro';
import Verdict from '../../components/blog/Verdict.astro';
import Card from '../../components/blog/Card.astro';

## The Confession

I have a confession to make: I've spent the better part of a decade paying for things I couldn't see.

Not in some metaphysical sense (though that too), but literally. Every month, thousands of dollars flowing to cloud providers for infrastructure that existed somewhere in the ether, governed by rules I couldn't read, priced by algorithms I couldn't understand, running code I'd never see.

And for years, I told myself this was fine. This was *progress*. This was *abstraction*.

But somewhere along the way, abstraction became opacity. Convenience became dependence. And "serverless" became a euphemism for "someone else's servers, someone else's rules, someone else's bill."

Lately, I've been dreaming.

<KeyPoint title="The Dream" accent="violet">
What if we could have the convenience of a modern PaaS without the black box? What if you could `git push` and have your code running in minutes, but also crack open the hood and see exactly how the engine works?
</KeyPoint>

This is not a product announcement. There's no GitHub repo to star, no landing page to visit, no waitlist to join. This is a thought experiment, a detailed sketch of something I've been calling **AnakinCloud** in my head. A meditation on the question that's been nagging at me since I deployed my first Heroku app in 2012: *Who owns this magic, and why can't I see the trick?*

<Callout type="warning" title="A Note on Reality">
**Nothing in this article exists as working code.** AnakinCloud is purely a thought experiment, a dream I'm thinking through in public. The CRDs, the operators, the CLI commands: they're all imaginary. But the philosophy? That's real. And maybe, if this resonates, the code could be too.
</Callout>

---

## Part I: The Economics of Opacity

### The Vercel Tax

Let's talk numbers, because numbers don't lie (though they can certainly mislead).

A typical Series A startup running on Vercel might see a bill like this:

<StatGrid
  stats={[
    { value: "$2,400", label: "Vercel Pro (12 seats)", accent: "error" },
    { value: "$850", label: "Bandwidth Overages", accent: "error" },
    { value: "$600", label: "Function Invocations", accent: "warning" },
    { value: "$450", label: "Edge Functions", accent: "warning" }
  ]}
  columns={4}
/>

That's **$4,300/month** for what amounts to a sophisticated `nginx` configuration and some Lambda functions with good DX.

Now, I'm not here to bash Vercel. They've done remarkable things for developer experience. But there's a fundamental tension at the heart of their model: **they profit from your ignorance**.

Not maliciously. It's just how the incentives align. The more magical the platform feels, the less you question the price. The more you depend on their proprietary edge network, the harder it is to leave. The more opaque the billing, the harder it is to optimize.

<Callout type="insight" title="The Hidden Cost">
The most expensive thing about cloud platforms isn't the infrastructure. It's the **switching cost**. Every proprietary feature, every custom runtime, every edge function that only works "here" is a brick in the wall between you and freedom.
</Callout>

### The EKS Paradox

"Fine," you say, "I'll just run Kubernetes myself."

And so begins a different kind of suffering.

AWS EKS promises you the power of Kubernetes without the operational burden. What it delivers is a $144/cluster/month control plane fee (that's just to *exist*), plus:

- NAT Gateway charges that would make a telecom executive blush
- Data transfer fees designed by someone who hates the concept of microservices
- Load balancer costs that scale linearly with your paranoia
- A complexity cliff that turns "just add another node" into a three-day Terraform adventure

<ComparisonTable
  headers={['The Promise', 'Vercel Reality', 'EKS Reality']}
  rows={[
    { feature: 'Getting started', colA: '5 minutes', colB: '5 hours (if lucky)' },
    { feature: 'Monthly cost (startup)', colA: '$4,000+', colB: '$2,500+' },
    { feature: 'Monthly cost (scale)', colA: '$15,000+', colB: '$8,000+' },
    { feature: 'Vendor lock-in', colA: 'High (proprietary)', colB: 'Medium (AWS-specific)' },
    { feature: 'Understanding your bill', colA: 'Impossible', colB: 'PhD required' },
    { feature: 'Exit strategy', colA: 'Rewrite everything', colB: 'Rewrite networking' },
  ]}
/>

The EKS paradox is this: you chose Kubernetes for portability, then spent six months building AWS-specific infrastructure that only works on AWS.

### Imagining a Different Path

What if there was a third option?

What if a platform *could* offer:
- The **developer experience** of Vercel (git push, get URL)
- The **power** of Kubernetes (scale anything, run anything)
- The **transparency** of open source (see every line of code)
- The **cost** of running your own infrastructure (minus the operational pain)

That's not a rhetorical question. It's the question I keep asking myself. And this article is my attempt to sketch out what the answer might look like.

---

## Part II: The Philosophy of Transparent Infrastructure

### Standing on the Shoulders of Giants

Here's what I believe: **the cloud shouldn't be magic; it should be machinery**.

Machinery can be understood. Machinery can be inspected. Machinery can be repaired by someone other than the original manufacturer.

The open-source community has spent two decades building the most sophisticated infrastructure machinery in human history. Kubernetes. Prometheus. Cilium. Traefik. PostgreSQL. Every piece is documented, battle-tested, and free as in freedom.

<KeyPoint title="The Core Belief" accent="rose">
The best platform would be a **transparent abstraction**, one that hides complexity without hiding knowledge. You should be able to `git push` on Monday and read the Kubernetes manifests on Tuesday. Both paths should be open.
</KeyPoint>

This is the philosophy I'm imagining for AnakinCloud:

<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem; margin: 2rem 0;">

<Card variant="violet" title="Everything is Open Source">
Not "open core" with premium features. Not "source available" with scary licenses. Actually, truly, fork-it-and-compete-with-us open source. MIT licensed. Forever.
</Card>

<Card variant="rose" title="Every Abstraction is Escapable">
Imagine `anakin deploy` that also shows you the CRDs it generates. Use the CLI forever, or graduate to raw `kubectl` when you're ready. Your choice.
</Card>

<Card variant="highlight" title="Pricing is Transparent">
Not "contact sales." Not "it depends." A public price list that shows exactly what everything costs, plus a calculator that tells you the truth before you commit.
</Card>

<Card title="Self-Hosting is First-Class">
Don't trust us? Run the entire platform on your own hardware. Same code, same features, zero vendor lock-in. The managed version would just be a convenience.
</Card>

</div>

### The Two-Path Promise

In this dream, when you use AnakinCloud, you're making a bet, but it's not a one-way bet.

**Path A: Managed Bliss**

You want the Vercel experience. Push code, get URLs. Never think about servers. That's fine. Imagine this:

```bash
# This is all you'd need
anakin login
anakin deploy

# Your app is live at https://your-app.anakin.cloud
```

The platform handles the Kubernetes. The databases. The certificates, the scaling, the monitoring, the backups. You write code; it keeps it running.

**Path B: Transparent Power**

But here's what would make it different: at any moment, you could peek behind the curtain.

```bash
# Show me what you're actually doing
anakin export --format=yaml > my-infrastructure.yaml

# Actually, let me just run this myself
kubectl apply -f my-infrastructure.yaml
```

That `my-infrastructure.yaml` file? It wouldn't be a proprietary format. It would be standard Kubernetes manifests with Custom Resource Definitions. You could take it anywhere. Run it on EKS. Run it on GKE. Run it on a Raspberry Pi cluster in your garage.

<Callout type="success" title="The Escape Hatch">
Imagine the only PaaS that *wants* you to be able to leave. Because if you *can* leave but *choose* to stay, that means it's actually providing value, not just lock-in.
</Callout>

### The Giants We'd Stand Upon

Before we go further, let's acknowledge the open-source projects that would make something like this possible. AnakinCloud wouldn't need to write much "new" code. It would integrate, configure, and compose:

<TechStack
  title="The Foundation"
  accent="primary"
  items={[
    { name: 'RKE2', category: 'Kubernetes', description: 'SUSE/Rancher\'s hardened distribution' },
    { name: 'Cilium', category: 'Networking', description: 'eBPF-powered CNI from Isovalent' },
    { name: 'CloudNativePG', category: 'Database', description: 'PostgreSQL operator, EDB-backed' },
    { name: 'Traefik', category: 'Ingress', description: 'Cloud-native edge router' },
    { name: 'Prometheus', category: 'Metrics', description: 'CNCF graduated project' },
    { name: 'Buildpacks', category: 'Build', description: 'Heroku + Pivotal collaboration' },
  ]}
/>

Every one of these projects has a corporate sponsor, a community of maintainers, and years of production hardening. We wouldn't be reinventing wheels; we'd be building a car.

---

## Part III: The Architecture of Honesty

Let's get technical. Because transparency isn't just philosophy. It's architecture. And even in a dream, the details matter.

### Why RKE2 on Hetzner?

These wouldn't be arbitrary choices. They're the result of asking: "What would we use if we had to bet our own money?"

<Callout type="violet" title="Why RKE2?">
**RKE2** (Rancher Kubernetes Engine 2) is Rancher's "next-generation Kubernetes distribution." It's what Rancher themselves run in production. Key advantages:

- **CIS hardened by default**: The security settings that would take you weeks to configure? Pre-applied.
- **Embedded etcd**: No separate etcd cluster to manage and worry about.
- **Automatic certificate rotation**: One less thing to wake you up at 3 AM.
- **100% open source**: Maintained by SUSE/Rancher with a track record of not rug-pulling their community.
</Callout>

<Callout type="rose" title="Why Hetzner?">
**Hetzner** is the European answer to "what if cloud providers charged reasonable prices?"

- **Carbon-neutral data centers**: Powered by renewable energy
- **True dedicated servers**: No noisy neighbors, starting at €39/month
- **Transparent pricing**: What you see is what you pay
- **20TB bandwidth included**: Yes, included. Not metered.
</Callout>

The numbers speak for themselves:

<StatGrid
  stats={[
    { value: "€4.51", label: "2 vCPU, 4GB RAM", accent: "success" },
    { value: "€15.59", label: "4 vCPU, 16GB RAM", accent: "success" },
    { value: "€36.59", label: "8 vCPU, 32GB RAM", accent: "success" },
    { value: "€0", label: "Ingress Traffic", accent: "success" }
  ]}
  columns={4}
/>

Compare that to AWS, where an equivalent `t3.medium` runs $30/month before you've transferred a single byte.

### The Control Plane

Here's what the architecture could look like, stripped of marketing:

```
┌─────────────────────────────────────────────────────────────────┐
│                     AnakinCloud Control Plane                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐             │
│  │   Project   │  │ Deployment  │  │  Database   │             │
│  │  Operator   │  │  Operator   │  │  Operator   │             │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘             │
│         │                │                │                     │
│         ▼                ▼                ▼                     │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │               Kubernetes API Server                      │   │
│  │        (CRDs + Native Resources + Secrets)               │   │
│  └─────────────────────────────────────────────────────────┘   │
│         │                │                │                     │
│         ▼                ▼                ▼                     │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐             │
│  │ Namespaces  │  │   Tekton    │  │ CloudNative │             │
│  │   RBAC      │  │  Pipelines  │  │     PG      │             │
│  │  Quotas     │  │    Pods     │  │  Clusters   │             │
│  └─────────────┘  └─────────────┘  └─────────────┘             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Nothing proprietary. Every box would be an open-source project. Every connection would be a standard Kubernetes API call.

---

## Part IV: Dreaming in Custom Resource Definitions

### Kubernetes, Extended

The real power of building on Kubernetes is the **Custom Resource Definition (CRD)** system. CRDs let you extend the Kubernetes API with your own resource types, and then those resources get all of Kubernetes' built-in superpowers: RBAC, audit logging, watch semantics, declarative reconciliation.

In this vision, AnakinCloud would define five core CRDs. Let me show you what they could look like, because in a transparent platform, you'd be reading these files when you want to understand what's happening.

### The Project CRD

Imagine a "project" as just a Kubernetes custom resource:

```yaml
apiVersion: anakin.cloud/v1alpha1
kind: Project
metadata:
  name: acme-corp
  namespace: anakin-system
spec:
  # Who owns this project
  owner:
    email: alice@acme.corp
    organizationId: org-123

  # Resource quotas - transparent limits
  quotas:
    maxCpu: "16"
    maxMemory: "32Gi"
    maxStorage: "100Gi"
    maxDeployments: 25

  # Networking
  domains:
    - "*.acme.corp"
    - "api.acme.io"

  # Billing tier (determines pricing)
  tier: startup

  # Feature flags
  features:
    previewEnvironments: true
    customDomains: true
    dedicatedDatabase: true
```

That's it. That's a project. No magic, no hidden state. Just a YAML file that tells the cluster what resources this project can use.

<Callout type="info" title="The Transparency Principle">
Every piece of configuration in this vision could be expressed as a Kubernetes resource. A CLI and dashboard would just be conveniences. They'd generate these resources for you. But you could always see, edit, and manage them directly.
</Callout>

### The Deployment CRD

When you'd run `anakin deploy`, here's what could get created:

```yaml
apiVersion: anakin.cloud/v1alpha1
kind: Deployment
metadata:
  name: api-server
  namespace: proj-acme-corp
  labels:
    anakin.cloud/project: acme-corp
    anakin.cloud/tier: startup
spec:
  # Source - supporting git or pre-built images
  source:
    git:
      repository: https://github.com/acme/api
      branch: main
      path: "."
      buildStrategy: buildpack  # or 'dockerfile'

  # Runtime configuration
  runtime:
    instances:
      min: 2
      max: 10
    resources:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "2Gi"

    # Health checks
    healthCheck:
      path: /health
      intervalSeconds: 10

    # Environment (references secrets properly)
    env:
      - name: NODE_ENV
        value: production
      - name: DATABASE_URL
        valueFrom:
          secretKeyRef:
            name: acme-corp-db
            key: connection-string

  # Scaling behavior
  scaling:
    metric: cpu
    targetUtilization: 70
    scaleDownDelay: 300s

  # Traffic management
  traffic:
    canary:
      enabled: false
      percentage: 0
    rateLimit:
      requestsPerSecond: 100
      burstSize: 200
```

This resource would get picked up by the **Deployment Operator**, which would:

1. **Clone your repository** (using a Tekton pipeline)
2. **Build your image** (using Cloud Native Buildpacks or your Dockerfile)
3. **Push to a registry** (Harbor, also open source)
4. **Create the Kubernetes Deployment, Service, and HPA**
5. **Configure Traefik ingress rules**
6. **Set up Prometheus scraping**

All of this would be visible. All of this would be overridable. All of this would be *yours*.

### The Database CRD

Managed databases are where PaaS providers really make their money. A simple PostgreSQL instance on AWS RDS can cost $50-100/month for something you could run yourself for $10.

Here's what a more honest approach could look like:

```yaml
apiVersion: anakin.cloud/v1alpha1
kind: Database
metadata:
  name: acme-corp-db
  namespace: proj-acme-corp
spec:
  engine: postgresql
  version: "16"
  tier: startup  # startup | growth | scale | enterprise

  # High availability
  replicas: 2  # Primary + 1 replica

  # Backup configuration
  backup:
    enabled: true
    schedule: "0 */6 * * *"  # Every 6 hours
    retention: 7d
    destination:
      s3:
        bucket: acme-backups
        endpoint: s3.eu-central-1.amazonaws.com

  # Connection pooling via PgBouncer
  pooler:
    enabled: true
    mode: transaction
    maxConnections: 100
```

Under the hood, this would use **CloudNativePG**, the most sophisticated Kubernetes operator for PostgreSQL. No wrapping it; using it directly.

<Callout type="violet" title="No Hidden Databases">
When you'd create a database through AnakinCloud, you'd get a real PostgreSQL instance running in your namespace. You could connect to it with `psql`. You could run `EXPLAIN ANALYZE`. You could even exec into the pod if you're brave. It would be your database.
</Callout>

---

## Part V: The Operator Pattern

### How Kubernetes Could Become a PaaS

The secret to this vision isn't any single piece of software. It's how they would work together.

Kubernetes has this beautiful concept: **the control loop**. You declare what you want (`spec`), and controllers continuously work to make reality match your declaration (`status`).

We could extend this pattern with operators:

```go
// Simplified reconciliation logic for the Deployment Operator
func (r *DeploymentReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    var deployment anakinv1.Deployment
    if err := r.Get(ctx, req.NamespacedName, &deployment); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }

    // Phase 1: Ensure build pipeline exists
    pipeline, err := r.ensureBuildPipeline(ctx, &deployment)
    if err != nil {
        return ctrl.Result{}, err
    }

    // Phase 2: If source changed, trigger new build
    if r.sourceChanged(&deployment) {
        run, err := r.triggerPipelineRun(ctx, &deployment, pipeline)
        if err != nil {
            return ctrl.Result{}, err
        }

        deployment.Status.Phase = anakinv1.DeploymentPhaseBuilding
        deployment.Status.CurrentBuild = run.Name
        return ctrl.Result{RequeueAfter: 10 * time.Second}, r.Status().Update(ctx, &deployment)
    }

    // Phase 3: If build complete, update Kubernetes resources
    if deployment.Status.Phase == anakinv1.DeploymentPhaseBuilding {
        build, err := r.getBuildStatus(ctx, deployment.Status.CurrentBuild)
        if err != nil {
            return ctrl.Result{}, err
        }

        if build.Succeeded() {
            deployment.Status.LatestImage = build.ImageDigest
            deployment.Status.Phase = anakinv1.DeploymentPhaseDeploying
        }
    }

    // Phase 4: Reconcile Kubernetes native resources
    if err := r.reconcileKubernetesDeployment(ctx, &deployment); err != nil {
        return ctrl.Result{}, err
    }
    if err := r.reconcileService(ctx, &deployment); err != nil {
        return ctrl.Result{}, err
    }
    if err := r.reconcileHPA(ctx, &deployment); err != nil {
        return ctrl.Result{}, err
    }
    if err := r.reconcileIngress(ctx, &deployment); err != nil {
        return ctrl.Result{}, err
    }

    deployment.Status.Phase = anakinv1.DeploymentPhaseRunning
    deployment.Status.URL = r.computeURL(&deployment)

    return ctrl.Result{}, r.Status().Update(ctx, &deployment)
}
```

The status of your deployment would always be queryable:

```bash
$ kubectl get deployment.anakin.cloud/api-server -o yaml

status:
  phase: Running
  currentBuild: build-abc123
  latestImage: registry.anakin.cloud/acme/api@sha256:def456...
  url: https://api.acme.corp
  replicas:
    desired: 3
    ready: 3
    available: 3
  conditions:
    - type: Available
      status: "True"
      lastTransitionTime: "2025-01-20T10:30:00Z"
```

<KeyPoint title="Debuggability" accent="success">
Imagine when something goes wrong, you don't need to contact support and wait for them to check their internal logs. Every resource would have a `status` field. Every operator would write events. Every component would log to a central Loki instance that *you* could query. The platform would be as debuggable for you as it is for the operators.
</KeyPoint>

---

## Part VI: Networking Without Nonsense

### Cilium: The Future of Container Networking

Traditional container networking works like this:
1. Packet arrives
2. iptables rules (thousands of them) evaluate the packet
3. Maybe some NAT happens
4. Packet finally gets where it's going

Cilium with eBPF:
1. Packet arrives
2. eBPF program in the kernel makes a decision
3. Done

<StatGrid
  stats={[
    { value: "40%", label: "Latency Reduction", accent: "success" },
    { value: "4x", label: "Throughput Increase", accent: "success" },
    { value: "0", label: "iptables Rules", accent: "violet" },
    { value: "L7", label: "Native Visibility", accent: "rose" }
  ]}
  columns={4}
/>

But it's not just about performance. Cilium gives us **network policies that actually work**:

```yaml
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: api-server-policy
  namespace: proj-acme-corp
spec:
  endpointSelector:
    matchLabels:
      app: api-server
  ingress:
    - fromEndpoints:
        - matchLabels:
            app: traefik
      toPorts:
        - ports:
            - port: "8080"
              protocol: TCP
  egress:
    - toEndpoints:
        - matchLabels:
            app: acme-corp-db
      toPorts:
        - ports:
            - port: "5432"
```

### Preview Environments

One of Vercel's killer features is preview deployments. Push a branch, get a URL. Here's how AnakinCloud could do the same, but transparently:

```yaml
apiVersion: anakin.cloud/v1alpha1
kind: Deployment
metadata:
  name: api-server
spec:
  previewEnvironments:
    enabled: true
    branchPattern: "feature/*|fix/*|preview/*"
    urlTemplate: "{{.Branch}}.preview.acme.corp"
    ttl: 24h
    resources:
      instances:
        min: 1
        max: 2
```

When you push `feature/new-auth`, the operator would:

1. Create a new `Deployment` resource: `api-server-feature-new-auth`
2. Build the branch
3. Deploy with preview-specific config
4. Create the ingress: `feature-new-auth.preview.acme.corp`
5. Post the URL as a GitHub comment

When the PR merges, the operator would clean up automatically.

<Callout type="rose" title="No Surprise Bills">
Preview environments would run on spot/preemptible instances with reduced resources. They'd be designed to be cheap enough that you don't think twice about creating them, and ephemeral enough that they don't accumulate cost.
</Callout>

---

## Part VII: Observability as a First-Class Citizen

### The Three Pillars, Done Right

"Observability" has become a buzzword, but the concept is simple: can you understand what your system is doing from the outside?

<TechStack
  title="Observability Stack"
  accent="violet"
  items={[
    { name: 'Prometheus', category: 'Metrics', description: 'Time-series database' },
    { name: 'Thanos', category: 'Long-term', description: 'Prometheus at scale' },
    { name: 'Loki', category: 'Logs', description: 'Like Prometheus, but for logs' },
    { name: 'Tempo', category: 'Traces', description: 'Distributed tracing backend' },
    { name: 'Grafana', category: 'Visualization', description: 'Dashboards and alerts' },
    { name: 'Alertmanager', category: 'Alerts', description: 'Alert routing and grouping' },
  ]}
/>

Every deployment would automatically get:

```yaml
# Automatically added to your pods
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"
```

Every project would get pre-built Grafana dashboards:
- **Application Overview**: Requests/sec, error rate, latency p50/p95/p99
- **Resource Usage**: CPU, memory, network I/O
- **Database Metrics**: Connections, query performance, replication lag
- **Cost Attribution**: How much is each component costing you

<KeyPoint title="Your Data, Your Access" accent="violet">
Unlike managed observability platforms (Datadog, New Relic, etc.), all of this data would live in your cluster. You could query it directly. You could export it. You could run your own Grafana instance against the APIs. Observability shouldn't be a vendor lock-in vector.
</KeyPoint>

---

## Part VIII: The Economics of Transparency

### A Real Cost Breakdown

Let's get specific. Here's what running a typical startup workload *could* cost on something like this:

**The Workload:**
- 3 production services (API, web, worker)
- 1 PostgreSQL database (high availability)
- 2 Redis instances (cache + queue)
- Auto-scaling from 2-10 instances per service
- 50GB storage
- 500GB/month egress

<ComparisonTable
  headers={['Component', 'AnakinCloud (Dream)', 'Vercel + PlanetScale + Upstash']}
  rows={[
    { feature: 'Compute (avg 6 instances)', colA: '€54/mo', colB: '$180/mo' },
    { feature: 'Database (HA PostgreSQL)', colA: '€45/mo', colB: '$99/mo' },
    { feature: 'Redis (2 instances)', colA: '€18/mo', colB: '$40/mo' },
    { feature: 'Storage (50GB)', colA: '€2.50/mo', colB: 'Included' },
    { feature: 'Egress (500GB)', colA: '€5/mo', colB: '$50/mo' },
    { feature: 'Platform fee', colA: '€49/mo', colB: '$100+/mo' },
  ]}
/>

<StatGrid
  stats={[
    { value: "€173", label: "AnakinCloud Total", accent: "success" },
    { value: "$469+", label: "Alternative Total", accent: "error" },
    { value: "63%", label: "Potential Savings", accent: "success" },
    { value: "100%", label: "Transparency", accent: "violet" }
  ]}
  columns={4}
/>

But here's the thing about transparent pricing: **you could verify it**.

A pricing calculator could show:
- Exactly which Hetzner instance types would be used
- The markup charged for management (imagine: 20%)
- What you'd pay if you self-hosted instead

```
Your estimated cost breakdown:
────────────────────────────────────────
Hetzner infrastructure:      €103.75/mo
AnakinCloud platform fee:     €49.00/mo  (support, updates, security)
AnakinCloud margin:           €20.75/mo  (20% of infrastructure)
────────────────────────────────────────
Total:                       €173.50/mo

Self-hosted estimate:        €103.75/mo  (infrastructure only)
```

Nothing hidden. If the margin isn't worth it to you, self-host. The platform would help you do it.

### The Business Model

<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem; margin: 2rem 0;">

<Card variant="violet" title="Self-Hosted">
**$0/forever**

- Full platform, all features
- MIT licensed
- Community support
- You handle operations

*For teams with Kubernetes expertise who want full control*
</Card>

<Card variant="rose" title="Managed">
**€49/project/month + infrastructure**

- Operations handled for you
- 24/7 monitoring
- Security patches
- Priority support

*For teams who want to focus on their product*
</Card>

</div>

<Callout type="insight" title="Sustainable Open Source">
This model would be sustainable because the managed service provides real value, not artificial scarcity. No crippling the self-hosted version or gating features behind paywalls. If you pay, it's because you want someone to handle the complexity, not because you have to.
</Callout>

---

## Part IX: The Self-Hosting Path

### Taking Full Control

Speaking of self-hosting, here's how it *could* work:

**1. Get the code**

```bash
git clone https://github.com/anakincloud/anakin-platform
cd anakin-platform
```

**2. Provision infrastructure**

Terraform modules for Hetzner, AWS, GCP, Azure, and bare metal:

```bash
cd terraform/hetzner
terraform init
terraform apply -var="cluster_name=my-platform"
```

**3. Install the platform**

```bash
helm repo add anakin https://charts.anakin.cloud
helm install anakin-platform anakin/platform \
  --namespace anakin-system \
  --create-namespace \
  --values my-values.yaml
```

**4. You're done**

Same CRDs, same operators, same capabilities. The only difference would be you're running the infrastructure.

<Callout type="warning" title="Fair Warning">
Self-hosting would mean you're responsible for:
- Kubernetes upgrades
- Security patches
- Backup verification
- Incident response at 3 AM

If that sounds exhausting, that's because it is. That's what you'd be paying for on a managed tier.
</Callout>

### The Graduation Path

Here's something most platforms won't tell you: in this vision, **you could graduate from managed to self-hosted at any time**.

1. Export your configuration: `anakin export --all > infrastructure.yaml`
2. Set up your own cluster
3. Apply the manifests: `kubectl apply -f infrastructure.yaml`
4. Update DNS
5. Done

Your data, your configuration, your choice. Always.

---

## Part X: Security Without Obscurity

### Defense in Depth, Visible in Depth

Security through obscurity is no security at all. Here's what a security model could look like, in the open:

**Namespace Isolation**

Every project would run in its own Kubernetes namespace with:
- Resource quotas (can't starve other tenants)
- Network policies (can't reach other tenants)
- RBAC (can't see other tenants' secrets)

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: project-quota
  namespace: proj-acme-corp
spec:
  hard:
    requests.cpu: "16"
    requests.memory: "32Gi"
    limits.cpu: "32"
    limits.memory: "64Gi"
    persistentvolumeclaims: "10"
```

**Network Policies by Default**

By default, pods couldn't talk to each other. You'd have to explicitly allow communication:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: proj-acme-corp
spec:
  podSelector: {}
  policyTypes:
    - Ingress
    - Egress
```

**Image Scanning**

Every image built through the pipeline would be scanned with Trivy before deployment. Critical vulnerabilities would block the deploy.

**Audit Logging**

Every API call logged: who, what, from where, when, and the response. Logs immutable and retained for 90 days minimum.

<KeyPoint title="Security is a Feature, Not a Secret" accent="rose">
A security model shouldn't be a competitive advantage to hide. It should be a promise to prove. Every security measure would be documented, auditable, and verifiable.
</KeyPoint>

---

## Part XI: The Plugin Ecosystem

### Extensibility Without Complexity

The core platform would handle compute, databases, and networking. But modern applications need more:

<TechStack
  title="Plugin Ecosystem"
  accent="rose"
  items={[
    { name: 'Redis', category: 'Cache', description: 'Via Redis Operator' },
    { name: 'RabbitMQ', category: 'Queue', description: 'Via RabbitMQ Operator' },
    { name: 'MinIO', category: 'Object Store', description: 'S3-compatible storage' },
    { name: 'Elasticsearch', category: 'Search', description: 'Via ECK Operator' },
    { name: 'MongoDB', category: 'NoSQL', description: 'Via Community Operator' },
    { name: 'Kafka', category: 'Streaming', description: 'Via Strimzi Operator' },
  ]}
/>

Each plugin would be:
1. **Optional**: only installed if you need it
2. **Transparent**: using upstream open-source operators
3. **Configurable**: via CRD abstraction or raw operator resources

**Want something without a plugin?**

```bash
# Install any Helm chart into your namespace
anakin addon install bitnami/kafka \
  --namespace proj-acme-corp \
  --values kafka-values.yaml
```

You wouldn't be locked into any ecosystem. The platform would be *additive*, not *restrictive*.

---

## Part XII: Imagining the Experience

### Five Minutes to Your First Deployment

Let's make this concrete. Imagine:

**1. Sign up**

```bash
brew install anakincloud/tap/anakin
anakin auth login
```

**2. Create a project**

```bash
anakin project create my-first-app
```

**3. Deploy**

```bash
cd my-existing-node-app
anakin deploy
```

That's it. The CLI would detect your framework, build your image, deploy to Kubernetes, set up HTTPS, and return your URL.

```
✓ Detected: Next.js 14 application
✓ Build completed in 45s
✓ Deployed to: https://my-first-app.anakin.cloud
✓ SSL certificate provisioned

Your app is live!
```

**4. Add a database**

```bash
anakin db create postgres --name main-db
```

Connection string automatically injected as `DATABASE_URL`.

**5. See what's running**

```bash
# Via CLI
anakin status

# Or see the Kubernetes resources directly
kubectl get all -n proj-my-first-app
```

<Verdict winner="rose" title="The AnakinCloud Promise">
Imagine going from `git clone` to production in 5 minutes. But unlike other platforms, you could *also* spend 5 hours understanding exactly what's running. Optimizing for both.
</Verdict>

---

## The Manifesto

I started this article with a confession: I've spent years paying for things I couldn't see.

AnakinCloud is my dream of an answer to that discomfort. It's a bet on several principles that I believe could work:

<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem; margin: 2rem 0;">

<Card variant="violet" title="Transparency Creates Trust">
When you can see how something works, you can decide if it's worth paying for. When you can't, you're just hoping.
</Card>

<Card variant="rose" title="Open Source is the Only Moat That Benefits Users">
Proprietary platforms compete on lock-in. Open-source platforms compete on value. I'd rather compete on value.
</Card>

<Card title="Abstraction and Understanding Aren't Opposites">
You should be able to ignore complexity, but you shouldn't be *forced* to. The best platforms are the ones you can grow into, not out of.
</Card>

<Card variant="highlight" title="The Cloud Shouldn't Be Mysterious">
Servers, networks, storage: these aren't magic. They're machines. Machines should be understandable by the people who depend on them.
</Card>

</div>

<KeyPoint title="An Invitation to Dream" accent="primary">
AnakinCloud doesn't exist yet. There's no code, no company, no waitlist. This is just an idea, a detailed sketch of what could be. But ideas have a way of becoming real when enough people believe in them.

If this resonates with you, I'd love to hear from you. Maybe it stays a dream. Maybe it becomes a side project. Maybe, just maybe, it becomes something more.
</KeyPoint>

---

## Why Am I Sharing This?

I could have kept this in my notes app forever. Another doc in the graveyard of ideas that never saw daylight.

But I believe in thinking in public. And I believe that sometimes the best way to figure out if something should exist is to describe it in detail and see if anyone else feels the same itch.

So consider this an open invitation:

- **Does this resonate?** Let me know. Maybe I'm not alone in this frustration.
- **Does this already exist?** Point me to it. I'd rather use something great than build something redundant.
- **Would you use this?** Tell me. The difference between a dream and a project is often just knowing someone else wants it too.
- **Want to build this together?** Now we're talking.

<Callout type="success" title="May the Source Be With You">
The name "AnakinCloud" is a nod to a certain chosen one who was supposed to bring balance to the Force. This dream is about bringing balance to cloud computing: transparency where there is opacity, choice where there is lock-in, understanding where there is mystery.

The giants have already built the machinery. We'd just be connecting the wires. And that's a story worth dreaming about.
</Callout>

---

*This article describes AnakinCloud, a thought experiment about transparent infrastructure. Nothing here exists as working code, yet. The vision is built on the shoulders of giants: RKE2, Kubernetes, CloudNativePG, Cilium, Traefik, Prometheus, and dozens of other projects maintained by thousands of contributors worldwide. The contribution would be integration and philosophy: the belief that infrastructure should be transparent, that abstraction should be escapable, and that the cloud belongs to everyone.*

*If you've read this far, thank you for dreaming with me.*
